{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3638b354-4412-422a-9f4a-dbc911d0af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RobertaSpanNer\n",
    "from transformers import RobertaConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_checkpoint = 'roberta-base'\n",
    "batch_size = 1\n",
    "short_label_list = ['O', 'substitute', 'before-insertions', 'after-insertions', 'revocation']\n",
    "num_labels = len(short_label_list)\n",
    "config = RobertaConfig.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "config.loss_type = 'ce'\n",
    "\n",
    "import torch.nn as nn\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RobertaSpanNer.from_pretrained('./roberta-base-finetuned-span/checkpoint-4380', config=config)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        start_logit, end_logit = self.model(input_ids, attention_mask)\n",
    "        return start_logit, end_logit\n",
    "    \n",
    "cu_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9dd001-d574-4825-afe2-c71498a09255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "         1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "         1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "         0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "         0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "         1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "         0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "         0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "         1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "         1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "         1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "         1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "         1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "         0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 1, 0, 0, 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Some standard imports\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "\n",
    "# Super Resolution model definition in PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "cu_model.eval()\n",
    "\n",
    "# Input to the model\n",
    "x1 = torch.randint(1, 100, (batch_size, 512), dtype=torch.int32)\n",
    "x2 = torch.randint(0, 2, (batch_size, 512), dtype=torch.int32)\n",
    "print(x2)\n",
    "#x = torch.tensor([[42]*8])\n",
    "torch_out = cu_model(x1, x2)\n",
    "# Export the model\n",
    "\n",
    "torch.onnx.export(cu_model,               # model being run\n",
    "                  (x1, x2),                         # model input (or a tuple for multiple inputs)\n",
    "                  \"span_ner.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=12,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input_ids', 'attention_mask'],   # the model's input names\n",
    "                  output_names = ['start_logit', 'end_logit'], # the model's output names\n",
    "                  dynamic_axes={'input_ids' : {0 : 'batch_size', 1:'sequence'},    # variable length axes\n",
    "                                'attention_mask' : {0 : 'batch_size', 1:'sequence'},\n",
    "                                'start_logit' : {0 : 'batch_size',1:'sequence'},\n",
    "                                'end_logit' : {0 : 'batch_size',1:'sequence'}}\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5616fa-40b1-4e62-968a-da1062b733f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randint(1, 100, (batch_size, 512))\n",
    "x1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee446b82-2668-4a75-b6f5-1ca1ad8ef512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 5])\n",
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_model = onnx.load(\"span_ner.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"span_ner.onnx\")\n",
    "\n",
    "# Input to the model\n",
    "batch_size = 1\n",
    "x = torch.randint(1, 100, (batch_size, 512))\n",
    "torch_out = cu_model(x1, x2)[0]\n",
    "print(torch_out.size())\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x1),\n",
    "              ort_session.get_inputs()[1].name: to_numpy(x2)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de4dfd-9237-49e2-a73c-b7bca070207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from models.seq2seq import *\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('./weights/annotation_gen_BART')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('./weights/annotation_gen_BART')\n",
    "#\n",
    "# ARTICLE_TO_SUMMARIZE = \"In Article 8 (civil-military coordination), in each of paragraphs 1 to 3 for “Member States” substitute “The Secretary of State”.\"\n",
    "# inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "#\n",
    "# # Generate Summary\n",
    "# summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=30, early_stopping=True)\n",
    "# [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained('./weights/annotation_gen_BART/')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        return self.model.generate(input_ids, num_beams=4, max_length=30, early_stopping=True)\n",
    "\n",
    "\n",
    "def export_seq2seq_onnx_representation(model_path='./weights/annotation_gen_BART', save_path='./weights/bart_onnx'):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    encoder = model.model.encoder\n",
    "    decoder = model.model.decoder\n",
    "    lm_head = model.lm_head\n",
    "\n",
    "    decoder_with_lm_head = CombinedDecoder(decoder, lm_head, model.config)\n",
    "    simplified_encoder = SimplifiedT5Encoder(encoder)\n",
    "    # Example sequence\n",
    "    input_ids = torch.tensor([[42] * 10])\n",
    "\n",
    "    # Exports to ONNX\n",
    "    _ = torch.onnx.export(\n",
    "        decoder_with_lm_head.eval(),\n",
    "        (input_ids, simplified_encoder(input_ids)),\n",
    "        f\"{save_path}/decoder.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        input_names=['input_ids', 'encoder_hidden_states'],\n",
    "        output_names=['hidden_states'],\n",
    "        dynamic_axes={\n",
    "            'input_ids': {0: 'batch', 1: 'sequence'},\n",
    "            'encoder_hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "            'hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "        })\n",
    "\n",
    "    _ = torch.onnx._export(\n",
    "        simplified_encoder.eval(),\n",
    "        input_ids,\n",
    "        f\"{save_path}/encoder.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=12,\n",
    "        input_names=['input_ids'],\n",
    "        output_names=['hidden_states'],\n",
    "        dynamic_axes={\n",
    "            'input_ids': {0: 'batch', 1: 'sequence'},\n",
    "            'hidden_states': {0: 'batch', 1: 'sequence'},\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# import onnxruntime\n",
    "# ort_session = onnxruntime.InferenceSession(\"./weights/bart_onnx/bart.onnx\")\n",
    "#\n",
    "# def to_numpy(tensor):\n",
    "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "#\n",
    "# # compute ONNX Runtime output prediction\n",
    "# x = torch.randint(high=100, size=(1, 256))\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "if __name__ == '__main__':\n",
    "    export_seq2seq_onnx_representation()\n",
    "    print(\"Model exported at \", './weights/bart_onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c16940-11fd-4e30-83fa-650104263b56",
   "metadata": {},
   "source": [
    "# TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8023837-1304-4424-aaf5-63e38cfe1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = torch.randint(1, 100, (batch_size, 512))\n",
    "traced_cell = torch.jit.trace(cu_model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a79418b-3846-42ca-a2c3-0f62a283c870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input_ids: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  _0, _1, = (self.model).forward(input_ids, )\n",
      "  return (_0, _1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc6671-72e3-495d-92d6-3ff121373a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.9",
   "language": "python",
   "name": "pytorch_1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
